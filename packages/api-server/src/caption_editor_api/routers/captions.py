"""Caption processing router."""

from typing import List, Optional
import tempfile
import os
from fastapi import APIRouter, UploadFile, File, HTTPException
from pydantic import BaseModel

router = APIRouter()


class CaptionSegment(BaseModel):
    """Caption segment model."""
    
    id: str
    start_time: float
    end_time: float
    text: str


class CaptionFile(BaseModel):
    """Caption file model."""
    
    segments: List[CaptionSegment]
    language: Optional[str] = "en"
    format: Optional[str] = "vtt"


class TranscriptionRequest(BaseModel):
    """Request model for AI transcription."""
    
    video_id: Optional[str] = None
    video_url: Optional[str] = None
    language: Optional[str] = "en"


class TranscriptionResponse(BaseModel):
    """Response model for AI transcription."""
    
    status: str
    job_id: Optional[str] = None
    captions: Optional[CaptionFile] = None
    message: str


class VideoUploadResponse(BaseModel):
    """Response model for video upload."""
    
    video_id: str
    filename: str
    size: int
    duration: Optional[float] = None
    message: str


@router.post("/videos/upload", response_model=VideoUploadResponse)
async def upload_video(file: UploadFile = File(...)):
    """Upload a video file for processing."""
    # Validate file extension
    if not file.filename:
        raise HTTPException(status_code=400, detail="No filename provided")
    
    # Check supported video formats
    supported_extensions = ['.mp4', '.mov', '.m4v']
    file_ext = os.path.splitext(file.filename)[1].lower()
    if file_ext not in supported_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported video format. Supported formats: {', '.join(supported_extensions)}"
        )
    
    # Create temporary file to store the video
    with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
        # Read and write file content
        content = await file.read()
        temp_file.write(content)
        temp_file_path = temp_file.name
    
    # Generate video ID (using filename + temp path for uniqueness)
    video_id = f"video_{os.path.basename(temp_file_path)}"
    
    # TODO: Extract video metadata (duration, etc.) using ffprobe or similar
    # For now, return basic file info
    return VideoUploadResponse(
        video_id=video_id,
        filename=file.filename,
        size=len(content),
        message=f"Video '{file.filename}' uploaded successfully. Ready for transcription."
    )


@router.post("/captions/upload", response_model=CaptionFile)
async def upload_caption_file(file: UploadFile = File(...)):
    """Upload and parse a caption file (VTT/SRT)."""
    if not file.filename or not file.filename.endswith(('.vtt', '.srt')):
        raise HTTPException(
            status_code=400, 
            detail="Only VTT and SRT files are supported"
        )
    
    # TODO: Implement actual file parsing
    # This is a placeholder response
    return CaptionFile(
        segments=[
            CaptionSegment(
                id="1",
                start_time=0.0,
                end_time=3.0,
                text="Sample caption segment"
            )
        ]
    )


@router.post("/captions/transcribe", response_model=TranscriptionResponse)
async def transcribe_video(request: TranscriptionRequest):
    """Start AI transcription of a video."""
    if not request.video_id and not request.video_url:
        raise HTTPException(
            status_code=400,
            detail="Either video_id (for uploaded video) or video_url is required"
        )
    
    # TODO: Implement AssemblyAI integration
    # For uploaded videos (video_id), we'll use the temporary file path
    # For video URLs, we'll pass the URL directly to AssemblyAI
    
    video_source = request.video_id if request.video_id else request.video_url
    
    return TranscriptionResponse(
        status="processing",
        job_id=f"job_{video_source}_{os.urandom(4).hex()}",
        message="Transcription started successfully"
    )


@router.get("/captions/transcribe/{job_id}", response_model=TranscriptionResponse)
async def get_transcription_result(job_id: str):
    """Get transcription result by job ID."""
    # TODO: Implement actual job status checking
    # This is a placeholder response
    return TranscriptionResponse(
        status="completed",
        job_id=job_id,
        captions=CaptionFile(
            segments=[
                CaptionSegment(
                    id="1",
                    start_time=0.0,
                    end_time=3.5,
                    text="This is a sample transcribed caption."
                ),
                CaptionSegment(
                    id="2", 
                    start_time=3.5,
                    end_time=7.0,
                    text="Generated by AI transcription service."
                )
            ]
        ),
        message="Transcription completed successfully"
    )